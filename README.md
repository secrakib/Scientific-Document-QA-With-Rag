# ğŸ”¬ Context-Aware Scientific Document Q/A System  
*A Retrieval-Augmented Generation (RAG) system for interactive scientific document exploration.*

![Demo](https://your-demo-gif-or-screenshot-link) <!-- Optional: Add a preview GIF or screenshot -->


[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)

---

## ğŸ“˜ Overview

This project enables **natural language interaction with scientific PDFs**, allowing users to query documents conversationally and receive **context-aware, memory-driven** responses.

By combining **RAG techniques, Gemini embeddings, and FAISS semantic search**, the system delivers accurate, contextually grounded answers while maintaining conversational memory across interactions.

---

## ğŸš€ Key Features

- ğŸ§  **Context-Aware Q/A** â€” Understands user queries in the context of prior conversation.  
- ğŸ” **Semantic Search with FAISS** â€” Retrieves the most relevant document chunks efficiently.  
- ğŸ”— **RAG Pipeline (LangChain)** â€” Connects retrieval, document, and memory chains for precise, dynamic reasoning.  
- ğŸ’¬ **Interactive UI** â€” Built with Streamlit for seamless document upload and exploration.  
- âœ… **Tested & Modular Design** â€” Comprehensive unit tests across all core modules.  

---

## ğŸ§© Architecture

      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚        User Interface          â”‚
      â”‚       (Streamlit App)          â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            Query & Context Input
                     â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚     LangChain RAG Pipeline     â”‚
      â”‚ (Retriever + Memory + QA Chain)â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         FAISS Index Search (Gemini)
                     â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚     Scientific PDF Chunks      â”‚
      â”‚     (Preprocessed via OCR)     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## âš™ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **LLM Framework** | LangChain |
| **Embeddings** | Gemini |
| **Vector Store** | FAISS |
| **Backend API** | FastAPI |
| **Frontend** | Streamlit |
| **Deployment** | Render |

---

## ğŸ§  How It Works

1. **Upload a PDF** â†’ The document is split into semantically meaningful chunks.  
2. **Embedding Generation** â†’ Each chunk is embedded using **Gemini embeddings**.  
3. **FAISS Indexing** â†’ Chunks are stored and retrieved efficiently via **FAISS**.  
4. **RAG Processing** â†’ A **LangChain pipeline** retrieves relevant chunks and generates responses.  
5. **Conversational Memory** â†’ User history is retained for context-aware answers.

---

## ğŸ§‘â€ğŸ’» Setup & Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/context-aware-scientific-qa.git
cd context-aware-scientific-qa

2. Create a Virtual Environment
python -m venv venv
source venv/bin/activate     # On macOS/Linux
venv\Scripts\activate        # On Windows

3. Install Dependencies
pip install -r requirements.txt

4. Run the Streamlit App
streamlit run app.py
```


ğŸ“š Example Query
```
User: â€œWhat is the main contribution of this paper?â€
System: â€œThe paper proposes a context-aware retrieval model for improved document-level question answering, leveraging multi-hop reasoning across sections.â€
```

ğŸ§± Project Structure
```
ğŸ“‚ context-aware-scientific-qa
â”œâ”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py              # FastAPI endpoints
â”‚   â”œâ”€â”€ rag_pipeline.py     # LangChain pipeline
â”‚   â”œâ”€â”€ retriever.py        # FAISS + Gemini retrieval
â”‚   â”œâ”€â”€ memory.py           # Conversation memory handler
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_retriever.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

ğŸ“ˆ Future Improvements
```
ğŸ”„ Support for multi-document context

ğŸ—£ï¸ Voice query integration

ğŸ§© Improved memory persistence with vectorized history

ğŸŒ Support for multilingual scientific texts
```


ğŸ“„ License
```
This project is licensed under the MIT License
```
